<!DOCTYPE HTML>
<html lang="en">

<head>
  <title>Lu Ling</title>

  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">

  <meta name="author" content="Lu Ling" />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="/style.css" />
  <link rel="canonical" href="/">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">
  <link rel="icon" href="images/purdue.png">

</head>



<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <h1>
                Lu Ling 
              </h1>
              <!-- <p>  My research interests focus on artificial intelligence in computer vision, including image editing and 3D content generation using learning-based 3D deep models. Besides, we collected a 10K real-world scene dataset to forge a path toward a foundation model for learning 3D representation.  </p> -->
              <p>  I am Lu Ling, a PhD candidate in the IDEADs Lab at Purdue University, advised by Prof. Aniket Bera.
                <br>
                <br> I am passionate about spatial intelligence and physical AI. I build scalable generative models for controllable 3D scene generation / world models, with an emphasis on data scaling through real-world data capture such as <a href='https://dl3dv-10k.github.io/DL3DV-10K/'> DL3DV-10K </a> and synthetic scene generation. The goal is to enable virtual content creation and editing, and to provide spatially grounded world understanding for embodied AI.
                <br>
                <br> I am a member of technical staff at <a href="https://www.worldlabs.ai/labs"> World Labs </a> in fall 2025, and a Research intern at <a href="https://research.nvidia.com/labs/dir/"> NVIDIA Deep Imagination Research </a> in summer and fall 2024. 
                <br>
                <br>
                <br> <strong style="color: #b31b1b;">I am looking for full-time Research Scientist and Member of Technical Staff positions in industry. Feel free to reach out to me via email!</strong>
              
              </p>
              
              <p style="text-align:center">
                <a href="mailto:ling58@purdue.edu"> Email</a> &nbsp;/&nbsp;
                <!-- <a href="https://drive.google.com/file/d/1sV_BxA5qk4CfRIh1t-t3riCrXKz8eAW8/view?usp=drive_link">CV</a> &nbsp;/&nbsp; -->
                <a href="https://scholar.google.com/citations?user=PuJyDnEAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/lu-ling-a528b5172/"> LinkedIn </a> &nbsp;/&nbsp;
                <a href="https://x.com/LuLing26466911"> Twitter </a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/profile-modified.png">
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>News</h2>
              <hr style="border: 0; border-top: 2px solid #b5936b; margin: 10px 0 15px 0;">
              <ul style="padding-left: 20px; line-height: 1.8;">
                <li><strong>[01/2026]</strong> &nbsp; <a href="https://research.nvidia.com/labs/dir/scenethesis/">Scenethesis</a>: an agentic framework for 3D scene generation, has been accepted by ICLR 2026!</li>
                <li><strong>[06/2025]</strong> &nbsp; <a href="https://dl3dv-10k.github.io/DL3DV-10K/">DL3DV-10K</a> is selected as CVPR 2025 demo presentation.</li>
                <li><strong>[06/2025]</strong> &nbsp; Invited talk at <a href="https://www.worldlabs.ai/">World Labs</a>.</li>
                <li><strong>[06/2024]</strong> &nbsp; <a href="https://dl3dv-10k.github.io/DL3DV-10K/">DL3DV-10K</a> has been accepted by CVPR 2024!</li>
                <li><strong>[06/2023]</strong> &nbsp; <a href="https://shengcn.github.io/DrBokeh/">Dr.Bokeh</a> and <a href="https://shengcn.github.io/PixHtLab/">PixHt-Lab</a> have been accepted by CVPR 2023!</li>
              </ul>
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Selected Publications</h2>
              <hr style="border: 0; border-top: 2px solid #b5936b; margin: 10px 0 15px 0;">
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/I-Scene.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>I-Scene: 3D Instance Models are Implicit Generalizable Spatial Learners</h3>
              <br>
              <strong>Lu Ling</strong>, <a href='https://gyhandy.github.io/'>Yunhao Ge</a>, <a href='https://shengcn.github.io/'>Yichen Sheng</a>, <a href='https://www.cs.purdue.edu/homes/ab/'>Aniket Bera</a>
              <br>

              
              <em>CVPR 2026</em>
              
              <br>
              
              <em>Feed-forward interactive 3D scene generation / world models. Strong generalizability and high fidelity for unseen layout and various spatial relations.</em>
              
              <br>
              
              <a href="https://luling06.github.io/I-Scene-project/">> proj</a> 
              
              
              <a href="https://arxiv.org/abs/2512.13683">> paper </a>  
              
              
              
              <a href="https://github.com/LuLing06/I-Scene-project">> code </a> 
              
              
              
              
              <p></p>
              

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/ScenethesisICCV2025.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Scenethesis: A Language and Vision Agentic Framework for 3D Scene Generation</h3>
              <br>
              <strong>Lu Ling</strong>, <a href='https://chenhsuanlin.bitbucket.io/'>Chen-Hsuan Lin</a>, <a href='https://tsungyilin.info/'>Tsung-Yi Lin</a>, <a href='https://scholar.google.com/citations?user=PAeRsxwAAAAJ&hl=zh-CN'>Yifan Ding</a>, <a href='https://zengxianyu.github.io/'>Yu Zeng</a>, <a href='https://shengcn.github.io/'>Yichen Sheng</a>, <a href='https://gyhandy.github.io/'>Yunhao Ge</a>, <a href='https://mingyuliu.net/'>Ming-Yu Liu</a>, <a href='https://www.cs.purdue.edu/homes/ab/'>Aniket Bera</a>, <a href='https://mli0603.github.io/'>Zhaoshuo Li</a>
              <br>

              
              <em>ICLR 2026 </em>
              
              <br>
              
              <em>An Agentic Framework for Text-to-3D Scene Generation. The generated scenes are diverse, interactive, realistic, and physically plausible for virtual content creation, editing, simulation, and embodied AI.</em>
              
              <br>
              
              <a href="https://research.nvidia.com/labs/dir/scenethesis">> proj</a> 
              
              
              <a href="https://arxiv.org/abs/2505.02836">> paper </a>  
              
              
              
              <a href="coming soon">> code </a> 
              
              
              
              
              <p></p>
              

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/DL3DV_10K.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>DL3DV-10K: A Large-Scale Scene Dataset for Deep Learning-based 3D Vision</h3>
              <br>
              <strong>Lu Ling</strong>, Yichen Sheng, Zhi Tu, Wentian Zhao, Cheng Xin, Kun Wan, Lantao Yu, Qianyu Guo, Zixun Yu, Yawen Lu, Xuanmao Li, Xingpeng Sun, Rohan Ashok, Aniruddha Mukherjee, Hao Kang, Xiangrui Kong,  <a href='https://www.ganghua.org/'>Gang Hua</a>, <a href='https://tianyi-zhang.github.io/'>Tianyi Zhang</a>,<a href='https://cs.purdue.edu/homes/bbenes/'> Bedrich Benes</a>, <a href='https://www.cs.purdue.edu/homes/ab/'>Aniket Bera</a>
              <br>

              
              <em>CVPR 2024</em>
              
              <br>
              
              <a href="https://huggingface.co/DL3DV" target="_blank" style="text-decoration: none;">
                <img src="https://img.shields.io/badge/ðŸ¤—_Downloads-73.6k-yellow?style=flat-square" alt="73.6k Downloads" style="vertical-align: middle;">
              </a>
              
              <br>
              
              <a href="https://dl3dv-10k.github.io/DL3DV-10K/">> proj</a> 
              
              
              <a href="https://arxiv.org/abs/2312.16256">> paper </a>  
              
              
              
              <a href="https://github.com/DL3DV-10K/Dataset">> code </a> 
              
              
              
              
              <p></p>
              

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/Dr_BOKEH.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Dr.Bokeh: DiffeRentiable Occlusion-aware Bokeh Rendering</h3>
              <br>
              Yichen Sheng, Zixun, Yu, <strong>Lu Ling</strong>, Zhiwen Cao, Cecilia Zhang, Xin Lu, Ke Xian, Haiting Lin, Bedrich Benes
              <br>

              
              <em>CVPR 2024</em>
              
              <br>
              
              <em>Lens blur effects in image compositing</em>
              
              <br>
              
              <a href="https://shengcn.github.io/DrBokeh/">> proj</a> 
              
              
              
              <a href="https://www.youtube.com/watch?v=iDGsC1BuO-A&ab_channel=YichenSheng">> video </a> 
              
              
              
              
              
              <p></p>
              

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/PixHtLab1_zoomed.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>PixHt-Lab: Pixel Height Based Light Effect Generation for Image Compositing</h3>
              <br>
              Yichen Sheng, Jianming Zhang, Julien Philip, Yannick Hold-Geoffroy, Xin Sun, HE Zhang,  <strong>Lu Ling</strong>, Bedrich Benes
              <br>

              
              <em>CVPR 2023 (highlight)</em>
              
              <br>
              
              <em>Light effects synthesis in image compositing</em>
              
              <br>
              
              
              <a href="https://shengcn.github.io/PixHtLab/">> paper </a>  
              
              
              
              <a href="https://github.com/ShengCN/PixHtLab-Src">> code </a> 
              
              
              
              
              <p></p>
              

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/framework.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Cooperating Graph Neural Networks with Deep Reinforcement Learning for Vaccine Prioritization</h3>
              <br>
              <strong>Lu Ling</strong>, Washim Uddin Mondal, Satish V. Ukkusuri
              <br>

              
              <em>IEEE Journal of Biomedical and Health Informatics (2024)</em>
              
              <br>
              
              <em>Reinforcement learning, graph neural network, deep learning, disease diffusion</em>
              
              <br>
              
              
              <a href="https://arxiv.org/abs/2305.05163">> paper </a>  
              
              
              
              
              
              
              <p></p>
              

            </td>
          </tr>
          
        </table>
        <br>
        <br>
        <br>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Academic Services</h2>
              <hr style="border: 0; border-top: 2px solid #b5936b; margin: 10px 0 15px 0;">
              <div style="background: #f9f9f9; padding: 15px 20px; border-radius: 6px;">
                <p style="margin: 0 0 10px 0; font-weight: bold;">Reviewer</p>
                <ul style="padding-left: 20px; line-height: 1.8; margin: 0;">
                  <li><strong>Computer Vision:</strong> CVPR, ICCV, ECCV, SIGGRAPH, TVCG</li>
                  <li><strong>Machine Learning:</strong> ICLR, NeurIPS, ICML</li>
                </ul>
              </div>
            </td>
          </tr>
        </table>
        <br>
        <br>
        <br>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Projects</h2>
              <hr style="border: 0; border-top: 2px solid #b5936b; margin: 10px 0 15px 0;">
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="images/GPPC.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Performance of Right-Turn Lane Designs at Intersections</h3>
              <br>
              <em>Project </em>
              <br>
              2020-12-04

              <br>
              
              
              <a href="https://docs.lib.purdue.edu/jtrp/1747/">paper</a> /
              
              
              
              
              
              
              
              
              
              <p></p>
              

            </td>
          </tr>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:0px">
              <p style="text-align:center;font-size:small;">
                Cool sites from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's website.</a>
                Thanks for <a style="font-size:small;" href="https://leonidk.com/">Leonid Keselman</a>'s Jekyll template
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
</body>

</html>

